{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LinkedIn Profile Classification - Rule-Based Baseline\n",
        "\n",
        "## Capstone Project: Predicting Career Domain and Seniority from LinkedIn Profiles\n",
        "\n",
        "**Author:** Veedan  \n",
        "**Institution:** Julius-Maximilians-Universit\u00e4t W\u00fcrzburg  \n",
        "**Date:** January 2026\n",
        "\n",
        "---\n",
        "\n",
        "### Project Overview\n",
        "\n",
        "This notebook implements the **Rule-Based Matching baseline** approach for predicting:\n",
        "1. **Department** (Career Domain) - 11 categories\n",
        "2. **Seniority Level** - 6 categories\n",
        "\n",
        "### Critical Data Discovery\n",
        "\n",
        "**Label Mismatch Issue:** The test data contains a \"Professional\" seniority level (35% of samples) that does NOT exist in the training label file. This represents mid-level professionals without explicit seniority indicators.\n",
        "\n",
        "### Approach\n",
        "\n",
        "Multi-strategy matching:\n",
        "1. **Exact Match** - Direct lookup from label CSV files\n",
        "2. **Keyword Matching** - Weighted multilingual keywords\n",
        "3. **Fuzzy Matching** - Sequence similarity\n",
        "4. **Intelligent Fallback** - \"Professional\" for ambiguous cases\n",
        "\n",
        "### Table of Contents\n",
        "1. Setup and Data Loading\n",
        "2. Exploratory Data Analysis\n",
        "3. Data Preprocessing\n",
        "4. Rule-Based Classifiers\n",
        "5. Model Evaluation\n",
        "6. Error Analysis\n",
        "7. Results Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 1. Setup and Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter, defaultdict\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, precision_recall_fscore_support\n",
        "import re\n",
        "from difflib import SequenceMatcher\n",
        "import warnings\n",
        "from functools import lru_cache\n",
        "import time\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['font.size'] = 11\n",
        "\n",
        "print('Libraries loaded successfully!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data\n",
        "df_seniority = pd.read_csv('seniority-v2.csv')\n",
        "df_department = pd.read_csv('department-v2.csv')\n",
        "\n",
        "with open('testdata.txt', 'r', encoding='utf-8') as f:\n",
        "    test_cvs = json.load(f)\n",
        "\n",
        "print('=' * 60)\n",
        "print('DATA LOADING SUMMARY')\n",
        "print('=' * 60)\n",
        "print(f'Seniority labels (training): {len(df_seniority):,} entries')\n",
        "print(f'Department labels (training): {len(df_department):,} entries')\n",
        "print(f'Test CVs: {len(test_cvs)} profiles')\n",
        "print(f'\\nDepartment categories: {sorted(df_department[\"label\"].unique())}')\n",
        "print(f'\\nSeniority categories (training): {sorted(df_seniority[\"label\"].unique())}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_active_jobs(cvs):\n",
        "    \"\"\"Extract only ACTIVE (current) job positions from CVs.\"\"\"\n",
        "    active_jobs = []\n",
        "    for cv in cvs:\n",
        "        for job in cv:\n",
        "            if job.get('status') == 'ACTIVE':\n",
        "                active_jobs.append(job)\n",
        "    return active_jobs\n",
        "\n",
        "test_active_jobs = extract_active_jobs(test_cvs)\n",
        "df_test = pd.DataFrame(test_active_jobs)\n",
        "\n",
        "print(f'Active jobs extracted: {len(df_test)}')\n",
        "print(f'\\nSeniority in TEST: {sorted(df_test[\"seniority\"].unique())}')\n",
        "print(f'Seniority in TRAIN: {sorted(df_seniority[\"label\"].unique())}')\n",
        "print(f'\\n\u26a0\ufe0f \"Professional\" is in TEST but NOT in TRAINING!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2. Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# Training distributions\n",
        "dept_train = df_department['label'].value_counts()\n",
        "axes[0, 0].barh(dept_train.index, dept_train.values, color='steelblue', alpha=0.7)\n",
        "axes[0, 0].set_title('Department (Training)', fontweight='bold')\n",
        "axes[0, 0].invert_yaxis()\n",
        "\n",
        "sen_train = df_seniority['label'].value_counts()\n",
        "axes[0, 1].barh(sen_train.index, sen_train.values, color='darkorange', alpha=0.7)\n",
        "axes[0, 1].set_title('Seniority (Training)', fontweight='bold')\n",
        "axes[0, 1].invert_yaxis()\n",
        "\n",
        "# Test distributions\n",
        "dept_test = df_test['department'].value_counts()\n",
        "axes[1, 0].barh(dept_test.index, dept_test.values, color='steelblue')\n",
        "axes[1, 0].set_title('Department (Test)', fontweight='bold')\n",
        "axes[1, 0].invert_yaxis()\n",
        "for i, v in enumerate(dept_test.values):\n",
        "    axes[1, 0].text(v + 2, i, f'{v} ({v/len(df_test)*100:.1f}%)', va='center', fontsize=9)\n",
        "\n",
        "sen_test = df_test['seniority'].value_counts()\n",
        "colors = ['red' if x == 'Professional' else 'darkorange' for x in sen_test.index]\n",
        "axes[1, 1].barh(sen_test.index, sen_test.values, color=colors)\n",
        "axes[1, 1].set_title('Seniority (Test) - Red=Not in Training!', fontweight='bold')\n",
        "axes[1, 1].invert_yaxis()\n",
        "for i, v in enumerate(sen_test.values):\n",
        "    axes[1, 1].text(v + 2, i, f'{v} ({v/len(df_test)*100:.1f}%)', va='center', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Job title analysis\n",
        "df_test['title_length'] = df_test['position'].apply(lambda x: len(str(x)) if pd.notna(x) else 0)\n",
        "df_test['title_words'] = df_test['position'].apply(lambda x: len(str(x).split()) if pd.notna(x) else 0)\n",
        "\n",
        "print('Job Title Statistics:')\n",
        "print('=' * 40)\n",
        "print(f'  Average length: {df_test[\"title_length\"].mean():.1f} chars')\n",
        "print(f'  Average words: {df_test[\"title_words\"].mean():.1f}')\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
        "axes[0].hist(df_test['title_length'], bins=30, color='teal', edgecolor='white')\n",
        "axes[0].set_title('Title Length Distribution', fontweight='bold')\n",
        "axes[0].set_xlabel('Characters')\n",
        "axes[1].hist(df_test['title_words'], bins=15, color='purple', edgecolor='white')\n",
        "axes[1].set_title('Title Word Count Distribution', fontweight='bold')\n",
        "axes[1].set_xlabel('Words')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample titles by seniority\n",
        "print('Sample Job Titles by Seniority:')\n",
        "print('=' * 70)\n",
        "for sen in ['Director', 'Management', 'Lead', 'Senior', 'Professional', 'Junior']:\n",
        "    samples = df_test[df_test['seniority'] == sen]['position'].head(4).tolist()\n",
        "    count = len(df_test[df_test['seniority'] == sen])\n",
        "    print(f'\\n{sen} (n={count}):')\n",
        "    for s in samples:\n",
        "        print(f'  \u2022 {str(s)[:60]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Language detection\n",
        "def detect_language(text):\n",
        "    if pd.isna(text): return 'Unknown'\n",
        "    text = str(text).lower()\n",
        "    german = ['gesch\u00e4ftsf\u00fchrer', 'leiter', 'mitarbeiter', '\u00e4', '\u00f6', '\u00fc', '\u00df']\n",
        "    french = ['directeur', 'responsable', 'chef de', '\u00e9', '\u00e8', '\u00ea']\n",
        "    g_score = sum(1 for p in german if p in text)\n",
        "    f_score = sum(1 for p in french if p in text)\n",
        "    if g_score > f_score and g_score > 0: return 'German'\n",
        "    if f_score > g_score and f_score > 0: return 'French'\n",
        "    return 'English/Other'\n",
        "\n",
        "df_test['language'] = df_test['position'].apply(detect_language)\n",
        "print('Language Distribution:')\n",
        "print(df_test['language'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### EDA Key Insights\n",
        "\n",
        "1. **Critical Label Mismatch**: \"Professional\" = 35% of test data, but NOT in training!\n",
        "2. **Class Imbalance**: \"Other\" dept (55%), \"Professional\" seniority (35%)\n",
        "3. **Multilingual**: ~25% German, ~5% French titles\n",
        "4. **Avg title**: 3-4 words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3. Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@lru_cache(maxsize=20000)\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Normalize text for matching.\"\"\"\n",
        "    if pd.isna(text) or text is None:\n",
        "        return ''\n",
        "    text = str(text).lower().strip()\n",
        "    text = re.sub(r'[^a-z\u00e4\u00f6\u00fc\u00df\u00e0\u00e2\u00e7\u00e9\u00e8\u00ea\u00eb\u00ee\u00ef\u00f4\u00fb\u00f9\u00fc\u00ff\u00f1\u00e6\u0153\\s]', ' ', text)\n",
        "    return ' '.join(text.split())\n",
        "\n",
        "def fast_similarity(s1, s2, threshold=0.75):\n",
        "    \"\"\"Calculate sequence similarity with early termination.\"\"\"\n",
        "    if not s1 or not s2: return 0.0\n",
        "    len_ratio = min(len(s1), len(s2)) / max(len(s1), len(s2))\n",
        "    if len_ratio < threshold - 0.2: return 0.0\n",
        "    return SequenceMatcher(None, s1, s2).ratio()\n",
        "\n",
        "# Test\n",
        "for t in ['Senior Engineer', 'Gesch\u00e4ftsf\u00fchrer', 'Chef de projet']:\n",
        "    print(f'{t} -> {preprocess_text(t)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 4. Rule-Based Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DepartmentClassifier:\n",
        "    def __init__(self, label_df):\n",
        "        self.valid_depts = set(label_df['label'].unique())\n",
        "        self.exact_match = {preprocess_text(r['text']): r['label'] \n",
        "                           for _, r in label_df.iterrows() if preprocess_text(r['text'])}\n",
        "        self.keywords = self._build_keywords()\n",
        "        self.examples = defaultdict(list)\n",
        "        for _, r in label_df.iterrows():\n",
        "            c = preprocess_text(r['text'])\n",
        "            if c: self.examples[r['label']].append(c)\n",
        "        print(f'  Exact matches: {len(self.exact_match):,}')\n",
        "    \n",
        "    def _build_keywords(self):\n",
        "        return {\n",
        "            'Sales': [('sales director', 5), ('sales manager', 5), ('vertriebsleiter', 5),\n",
        "                     ('sales', 4), ('vertrieb', 4), ('verkauf', 4), ('account manager', 4),\n",
        "                     ('account executive', 5), ('key account', 4), ('vente', 4), ('commercial', 3)],\n",
        "            'Marketing': [('marketing manager', 5), ('marketing director', 5), ('marketingleiter', 5),\n",
        "                         ('digital marketing', 5), ('marketing', 4), ('brand', 3), ('pr ', 4),\n",
        "                         ('social media', 4), ('seo', 4), ('kommunikation', 3), ('werbung', 4),\n",
        "                         ('charg\u00e9 de communication', 5), ('charg\u00e9e de marketing', 5)],\n",
        "            'Information Technology': [('software engineer', 5), ('software developer', 5), \n",
        "                         ('softwareentwickler', 5), ('data scientist', 5), ('data engineer', 5),\n",
        "                         ('it manager', 5), ('cto', 5), ('cio', 5), ('solutions architect', 5),\n",
        "                         ('developer', 4), ('entwickler', 4), ('devops', 5), ('cloud', 4),\n",
        "                         ('network', 3), ('database', 4), ('sap', 4), ('it ', 4), ('informatik', 4),\n",
        "                         ('systemadministrator', 5), ('architect', 3), ('technical', 3)],\n",
        "            'Human Resources': [('human resources', 5), ('hr manager', 5), ('personalleiter', 5),\n",
        "                         ('hr business partner', 5), ('hrbp', 5), ('recruiter', 5), ('recruiting', 4),\n",
        "                         ('talent acquisition', 5), ('hr ', 4), ('personal', 3), ('drh', 5)],\n",
        "            'Project Management': [('project manager', 5), ('projektleiter', 5), ('projektmanager', 5),\n",
        "                         ('program manager', 5), ('chef de projet', 5), ('scrum master', 5),\n",
        "                         ('pmo', 5), ('agile coach', 5), ('product owner', 4), ('projektmanagement', 4)],\n",
        "            'Business Development': [('business development', 5), ('bizdev', 5), ('bd manager', 5),\n",
        "                         ('partnerships', 4), ('strategic partnerships', 5), ('gesch\u00e4ftsentwicklung', 5)],\n",
        "            'Customer Support': [('customer service', 5), ('customer support', 5), ('kundenservice', 5),\n",
        "                         ('customer success', 5), ('helpdesk', 5), ('service client', 5),\n",
        "                         ('technical support', 5), ('customer care', 4)],\n",
        "            'Administrative': [('office manager', 5), ('executive assistant', 5), ('secretary', 4),\n",
        "                         ('administrative', 4), ('verwaltung', 4), ('sachbearbeiter', 3),\n",
        "                         ('buchhalter', 4), ('buchhalterin', 4), ('assistenz', 3)],\n",
        "            'Consulting': [('management consultant', 5), ('consultant', 4), ('consulting', 4),\n",
        "                         ('berater', 4), ('beratung', 4), ('unternehmensberater', 5), ('advisory', 4)],\n",
        "            'Purchasing': [('purchasing', 5), ('procurement', 5), ('einkauf', 5), ('eink\u00e4ufer', 5),\n",
        "                         ('buyer', 4), ('sourcing', 4), ('supply chain', 4), ('achat', 4)],\n",
        "        }\n",
        "    \n",
        "    def predict(self, text):\n",
        "        if pd.isna(text): return 'Other'\n",
        "        cleaned = preprocess_text(text)\n",
        "        if not cleaned: return 'Other'\n",
        "        \n",
        "        # Exact match\n",
        "        if cleaned in self.exact_match:\n",
        "            return self.exact_match[cleaned]\n",
        "        \n",
        "        # Keyword matching\n",
        "        scores = defaultdict(float)\n",
        "        for dept, kws in self.keywords.items():\n",
        "            if dept not in self.valid_depts: continue\n",
        "            for kw, weight in kws:\n",
        "                if kw in cleaned:\n",
        "                    scores[dept] += weight + len(kw.split()) * 0.3\n",
        "        \n",
        "        if scores:\n",
        "            best = max(scores, key=scores.get)\n",
        "            if scores[best] >= 4.0:\n",
        "                return best\n",
        "        \n",
        "        # Fuzzy match\n",
        "        candidates = list(scores.keys()) if scores else list(self.valid_depts)\n",
        "        best_sim, best_dept = 0, None\n",
        "        for dept in candidates:\n",
        "            for ex in self.examples.get(dept, [])[:40]:\n",
        "                sim = fast_similarity(cleaned, ex)\n",
        "                if sim > best_sim:\n",
        "                    best_sim, best_dept = sim, dept\n",
        "                    if sim > 0.92: return best_dept\n",
        "        \n",
        "        if best_sim > 0.78: return best_dept\n",
        "        if scores: return max(scores, key=scores.get)\n",
        "        return 'Other'\n",
        "    \n",
        "    def predict_batch(self, texts):\n",
        "        return [self.predict(t) for t in texts]\n",
        "\n",
        "print('Initializing Department Classifier...')\n",
        "dept_clf = DepartmentClassifier(df_department)\n",
        "print('\u2713 Ready!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SeniorityClassifier:\n",
        "    \"\"\"Handles 'Professional' label that exists in test but not training.\"\"\"\n",
        "    \n",
        "    HIERARCHY = ['Director', 'Management', 'Lead', 'Senior', 'Professional', 'Junior']\n",
        "    \n",
        "    def __init__(self, label_df):\n",
        "        self.train_levels = set(label_df['label'].unique())\n",
        "        self.valid_levels = self.train_levels | {'Professional'}\n",
        "        self.exact_match = {preprocess_text(r['text']): r['label'] \n",
        "                           for _, r in label_df.iterrows() if preprocess_text(r['text'])}\n",
        "        self.patterns = self._build_patterns()\n",
        "        self.examples = defaultdict(list)\n",
        "        for _, r in label_df.iterrows():\n",
        "            c = preprocess_text(r['text'])\n",
        "            if c: self.examples[r['label']].append(c)\n",
        "        print(f'  Exact matches: {len(self.exact_match):,}')\n",
        "        print(f'  Valid levels: {sorted(self.valid_levels)}')\n",
        "    \n",
        "    def _build_patterns(self):\n",
        "        return {\n",
        "            'Director': [\n",
        "                ('ceo', 6), ('chief executive', 6), ('gesch\u00e4ftsf\u00fchrer', 6), ('gesch\u00e4ftsf\u00fchrerin', 6),\n",
        "                ('cto', 6), ('cfo', 6), ('coo', 6), ('cmo', 6), ('cio', 6), ('chief ', 6),\n",
        "                ('president', 5), ('vice president', 5), ('vp ', 5), ('svp', 6), ('evp', 6),\n",
        "                ('managing director', 6), ('general manager', 5),\n",
        "                ('director', 5), ('directeur', 5), ('direktor', 5),\n",
        "                ('vorstand', 6), ('prokurist', 5), ('prokuristin', 5), ('inhaber', 5),\n",
        "                ('founder', 5), ('owner', 5), ('partner', 4), ('shareholder', 4), ('member of', 4),\n",
        "            ],\n",
        "            'Management': [\n",
        "                ('head of', 5), ('leiter', 5), ('leiterin', 5), ('leitung', 4),\n",
        "                ('abteilungsleiter', 5), ('bereichsleiter', 5),\n",
        "                ('manager', 4), ('managerin', 4),\n",
        "                ('group manager', 5), ('department head', 5),\n",
        "                ('responsable', 4), ('supervisor', 4),\n",
        "            ],\n",
        "            'Lead': [\n",
        "                ('team lead', 5), ('teamlead', 5), ('tech lead', 5), ('technical lead', 5),\n",
        "                ('lead developer', 5), ('lead engineer', 5), ('teamleiter', 5),\n",
        "                ('lead ', 4), ('group leader', 5), ('team leader', 5),\n",
        "                ('chef de projet', 4), ('coordinator', 3),\n",
        "                ('scrum master', 4), ('product owner', 4),\n",
        "            ],\n",
        "            'Senior': [\n",
        "                ('senior', 5), ('sr ', 5), ('sr.', 5),\n",
        "                ('principal', 5), ('staff ', 4),\n",
        "                ('expert', 4), ('experte', 4),\n",
        "                ('spezialist', 3), ('specialist', 3), ('architect', 3),\n",
        "            ],\n",
        "            'Junior': [\n",
        "                ('junior', 5), ('jr ', 5), ('jr.', 5),\n",
        "                ('trainee', 5), ('praktikant', 5), ('praktikantin', 5),\n",
        "                ('intern', 5), ('stagiaire', 5), ('werkstudent', 5),\n",
        "                ('graduate', 4), ('entry level', 5),\n",
        "                ('apprentice', 5), ('azubi', 5),\n",
        "                ('associate', 3), ('assistant', 3), ('analyst', 2),\n",
        "            ],\n",
        "            'Professional': [\n",
        "                ('consultant', 2), ('engineer', 2), ('developer', 2),\n",
        "                ('administrator', 2), ('generalist', 3),\n",
        "                ('betriebswirt', 3), ('fachkraft', 3),\n",
        "            ],\n",
        "        }\n",
        "    \n",
        "    def predict(self, text):\n",
        "        if pd.isna(text): return 'Professional'\n",
        "        cleaned = preprocess_text(text)\n",
        "        if not cleaned: return 'Professional'\n",
        "        \n",
        "        # Exact match\n",
        "        if cleaned in self.exact_match:\n",
        "            return self.exact_match[cleaned]\n",
        "        \n",
        "        # Pattern matching\n",
        "        scores = {}\n",
        "        for level in self.HIERARCHY:\n",
        "            if level not in self.patterns: continue\n",
        "            score = sum(w for p, w in self.patterns[level] if p in cleaned)\n",
        "            if score > 0: scores[level] = score\n",
        "        \n",
        "        if scores:\n",
        "            max_score = max(scores.values())\n",
        "            for level in self.HIERARCHY:\n",
        "                if level in scores and scores[level] >= max_score - 1:\n",
        "                    return level\n",
        "        \n",
        "        # Fuzzy match\n",
        "        best_sim, best_level = 0, None\n",
        "        for level in self.train_levels:\n",
        "            for ex in self.examples.get(level, [])[:25]:\n",
        "                sim = fast_similarity(cleaned, ex)\n",
        "                if sim > best_sim:\n",
        "                    best_sim, best_level = sim, level\n",
        "                    if sim > 0.90: return best_level\n",
        "        \n",
        "        if best_sim > 0.75: return best_level\n",
        "        return 'Professional'\n",
        "    \n",
        "    def predict_batch(self, texts):\n",
        "        return [self.predict(t) for t in texts]\n",
        "\n",
        "print('\\nInitializing Seniority Classifier...')\n",
        "sen_clf = SeniorityClassifier(df_seniority)\n",
        "print('\u2713 Ready!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sanity check\n",
        "tests = ['CEO', 'Gesch\u00e4ftsf\u00fchrer', 'Head of Marketing', 'Team Lead', 'Senior Engineer',\n",
        "         'Solutions Architect', 'IT-Systemadministrator', 'Junior Analyst', 'Trainee']\n",
        "\n",
        "print('Sanity Check:')\n",
        "print('=' * 75)\n",
        "print(f'{\"Title\":<35} {\"Department\":<22} {\"Seniority\":<15}')\n",
        "print('-' * 75)\n",
        "for t in tests:\n",
        "    print(f'{t:<35} {dept_clf.predict(t):<22} {sen_clf.predict(t):<15}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 5. Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Generating predictions...')\n",
        "start = time.time()\n",
        "df_test['pred_dept'] = dept_clf.predict_batch(df_test['position'].tolist())\n",
        "df_test['pred_sen'] = sen_clf.predict_batch(df_test['position'].tolist())\n",
        "elapsed = time.time() - start\n",
        "print(f'\u2713 Done in {elapsed:.2f}s ({len(df_test)/elapsed:.0f}/sec)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dept_acc = accuracy_score(df_test['department'], df_test['pred_dept'])\n",
        "sen_acc = accuracy_score(df_test['seniority'], df_test['pred_sen'])\n",
        "dept_f1_m = f1_score(df_test['department'], df_test['pred_dept'], average='macro', zero_division=0)\n",
        "sen_f1_m = f1_score(df_test['seniority'], df_test['pred_sen'], average='macro', zero_division=0)\n",
        "dept_f1_w = f1_score(df_test['department'], df_test['pred_dept'], average='weighted', zero_division=0)\n",
        "sen_f1_w = f1_score(df_test['seniority'], df_test['pred_sen'], average='weighted', zero_division=0)\n",
        "\n",
        "print('\\n' + '=' * 65)\n",
        "print('           RULE-BASED BASELINE RESULTS')\n",
        "print('=' * 65)\n",
        "print(f'\\n{\"Metric\":<30} {\"Department\":>15} {\"Seniority\":>15}')\n",
        "print('-' * 65)\n",
        "print(f'{\"Accuracy\":<30} {dept_acc*100:>14.2f}% {sen_acc*100:>14.2f}%')\n",
        "print(f'{\"F1 (Macro)\":<30} {dept_f1_m:>15.3f} {sen_f1_m:>15.3f}')\n",
        "print(f'{\"F1 (Weighted)\":<30} {dept_f1_w:>15.3f} {sen_f1_w:>15.3f}')\n",
        "print('=' * 65)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('\\nDEPARTMENT CLASSIFICATION REPORT')\n",
        "print('=' * 70)\n",
        "print(classification_report(df_test['department'], df_test['pred_dept'], zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('\\nSENIORITY CLASSIFICATION REPORT')\n",
        "print('=' * 70)\n",
        "print(classification_report(df_test['seniority'], df_test['pred_sen'], zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion matrices\n",
        "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
        "\n",
        "dept_labels = sorted(df_test['department'].unique())\n",
        "cm_dept = confusion_matrix(df_test['department'], df_test['pred_dept'], labels=dept_labels)\n",
        "sns.heatmap(cm_dept, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=dept_labels, yticklabels=dept_labels, ax=axes[0])\n",
        "axes[0].set_title(f'Department (Acc: {dept_acc*100:.1f}%)', fontweight='bold')\n",
        "axes[0].set_xlabel('Predicted')\n",
        "axes[0].set_ylabel('Actual')\n",
        "axes[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "sen_labels = sorted(df_test['seniority'].unique())\n",
        "cm_sen = confusion_matrix(df_test['seniority'], df_test['pred_sen'], labels=sen_labels)\n",
        "sns.heatmap(cm_sen, annot=True, fmt='d', cmap='Oranges',\n",
        "            xticklabels=sen_labels, yticklabels=sen_labels, ax=axes[1])\n",
        "axes[1].set_title(f'Seniority (Acc: {sen_acc*100:.1f}%)', fontweight='bold')\n",
        "axes[1].set_xlabel('Predicted')\n",
        "axes[1].set_ylabel('Actual')\n",
        "axes[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Per-class F1\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
        "\n",
        "d_p, d_r, d_f1, d_s = precision_recall_fscore_support(df_test['department'], df_test['pred_dept'], \n",
        "                                                       labels=dept_labels, zero_division=0)\n",
        "colors = ['green' if f > 0.5 else 'orange' if f > 0.3 else 'red' for f in d_f1]\n",
        "axes[0].barh(dept_labels, d_f1, color=colors, alpha=0.7)\n",
        "axes[0].set_title('Department F1 by Class', fontweight='bold')\n",
        "axes[0].set_xlim(0, 1)\n",
        "axes[0].axvline(0.5, color='gray', linestyle='--', alpha=0.5)\n",
        "for i, (f, s) in enumerate(zip(d_f1, d_s)):\n",
        "    axes[0].text(f + 0.02, i, f'{f:.2f} (n={s})', va='center', fontsize=9)\n",
        "axes[0].invert_yaxis()\n",
        "\n",
        "s_p, s_r, s_f1, s_s = precision_recall_fscore_support(df_test['seniority'], df_test['pred_sen'], \n",
        "                                                       labels=sen_labels, zero_division=0)\n",
        "colors = ['green' if f > 0.5 else 'orange' if f > 0.3 else 'red' for f in s_f1]\n",
        "axes[1].barh(sen_labels, s_f1, color=colors, alpha=0.7)\n",
        "axes[1].set_title('Seniority F1 by Class', fontweight='bold')\n",
        "axes[1].set_xlim(0, 1)\n",
        "axes[1].axvline(0.5, color='gray', linestyle='--', alpha=0.5)\n",
        "for i, (f, s) in enumerate(zip(s_f1, s_s)):\n",
        "    axes[1].text(f + 0.02, i, f'{f:.2f} (n={s})', va='center', fontsize=9)\n",
        "axes[1].invert_yaxis()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 6. Error Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test['dept_ok'] = df_test['department'] == df_test['pred_dept']\n",
        "df_test['sen_ok'] = df_test['seniority'] == df_test['pred_sen']\n",
        "\n",
        "print('Error Summary:')\n",
        "print('=' * 55)\n",
        "print(f'Department errors: {(~df_test[\"dept_ok\"]).sum()} ({(~df_test[\"dept_ok\"]).mean()*100:.1f}%)')\n",
        "print(f'Seniority errors: {(~df_test[\"sen_ok\"]).sum()} ({(~df_test[\"sen_ok\"]).mean()*100:.1f}%)')\n",
        "print(f'Both correct: {(df_test[\"dept_ok\"] & df_test[\"sen_ok\"]).sum()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Top error patterns\n",
        "dept_err = df_test[~df_test['dept_ok']]\n",
        "patterns = dept_err.groupby(['department', 'pred_dept']).size().reset_index(name='n')\n",
        "patterns = patterns.sort_values('n', ascending=False).head(10)\n",
        "\n",
        "print('\\nTop Department Error Patterns:')\n",
        "print('=' * 60)\n",
        "print(f'{\"Actual\":<22} {\"Predicted\":<22} {\"Count\":>10}')\n",
        "print('-' * 60)\n",
        "for _, r in patterns.iterrows():\n",
        "    print(f'{r[\"department\"]:<22} {r[\"pred_dept\"]:<22} {r[\"n\"]:>10}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sen_err = df_test[~df_test['sen_ok']]\n",
        "patterns = sen_err.groupby(['seniority', 'pred_sen']).size().reset_index(name='n')\n",
        "patterns = patterns.sort_values('n', ascending=False).head(10)\n",
        "\n",
        "print('\\nTop Seniority Error Patterns:')\n",
        "print('=' * 55)\n",
        "print(f'{\"Actual\":<18} {\"Predicted\":<18} {\"Count\":>10}')\n",
        "print('-' * 55)\n",
        "for _, r in patterns.iterrows():\n",
        "    print(f'{r[\"seniority\"]:<18} {r[\"pred_sen\"]:<18} {r[\"n\"]:>10}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample errors\n",
        "print('\\nSample Misclassified Titles:')\n",
        "print('=' * 80)\n",
        "for _, p in patterns.head(3).iterrows():\n",
        "    samples = sen_err[(sen_err['seniority']==p['seniority']) & \n",
        "                      (sen_err['pred_sen']==p['pred_sen'])]['position'].head(3)\n",
        "    print(f'\\n{p[\"seniority\"]} -> {p[\"pred_sen\"]} (n={p[\"n\"]}):')\n",
        "    for s in samples:\n",
        "        print(f'  \u2022 {str(s)[:65]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Accuracy by language\n",
        "lang_acc = df_test.groupby('language').agg({'dept_ok': 'mean', 'sen_ok': 'mean', 'position': 'count'})\n",
        "lang_acc.columns = ['Dept Acc', 'Sen Acc', 'Count']\n",
        "\n",
        "print('\\nAccuracy by Language:')\n",
        "print('=' * 55)\n",
        "print(f'{\"Language\":<18} {\"Dept Acc\":>12} {\"Sen Acc\":>12} {\"Count\":>10}')\n",
        "print('-' * 55)\n",
        "for idx, r in lang_acc.iterrows():\n",
        "    print(f'{idx:<18} {r[\"Dept Acc\"]*100:>11.1f}% {r[\"Sen Acc\"]*100:>11.1f}% {int(r[\"Count\"]):>10}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 7. Results Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save results\n",
        "cols = ['position', 'organization', 'department', 'pred_dept', 'seniority', 'pred_sen', 'dept_ok', 'sen_ok']\n",
        "df_test[cols].to_csv('predictions_rule_based.csv', index=False)\n",
        "print('\u2713 Saved predictions to predictions_rule_based.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('''\n",
        "\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n",
        "\u2551              RULE-BASED BASELINE - FINAL SUMMARY                 \u2551\n",
        "\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n",
        "''')\n",
        "print(f'''\n",
        "PERFORMANCE\n",
        "{'\u2500' * 50}\n",
        "Department:  Accuracy={dept_acc*100:.1f}%, F1(macro)={dept_f1_m:.3f}\n",
        "Seniority:   Accuracy={sen_acc*100:.1f}%, F1(macro)={sen_f1_m:.3f}\n",
        "\n",
        "METHODOLOGY\n",
        "{'\u2500' * 50}\n",
        "\u2022 Multi-strategy: Exact \u2192 Keywords \u2192 Fuzzy \u2192 Fallback\n",
        "\u2022 Multilingual keywords (EN, DE, FR)\n",
        "\u2022 Handles \"Professional\" (test-only label)\n",
        "\u2022 Hierarchical seniority resolution\n",
        "\n",
        "KEY FINDINGS\n",
        "{'\u2500' * 50}\n",
        "\u2022 \"Professional\" label (35% of test) not in training\n",
        "\u2022 Department \"Other\" dominates (55%)\n",
        "\u2022 German titles: ~25% of data\n",
        "\n",
        "NEXT STEPS\n",
        "{'\u2500' * 50}\n",
        "1. TF-IDF + Logistic Regression\n",
        "2. Embedding-based (Sentence-BERT)\n",
        "3. Fine-tuned transformer\n",
        "4. Include organization name as feature\n",
        "''')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Appendix: GenAI Usage\n",
        "\n",
        "**AI Tools Used:** Claude (Anthropic)\n",
        "\n",
        "**Uses:**\n",
        "- Keyword list generation (multilingual)\n",
        "- Code structure and evaluation pipeline\n",
        "- Documentation and markdown\n",
        "\n",
        "**Human Contributions:**\n",
        "- Problem definition\n",
        "- Data exploration\n",
        "- Discovery of \"Professional\" label issue\n",
        "- Threshold tuning\n",
        "- Result interpretation"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}