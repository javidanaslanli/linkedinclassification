{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBq3YBZODY-A"
      },
      "source": [
        "# LinkedIn Classification - SetFit V3: Concept Pre-Knowledge\n",
        "\n",
        "## Capstone Project: Julius-Maximilians-Universität Würzburg\n",
        "\n",
        "### Architecture:\n",
        "```\n",
        "STAGE 1: Model learns CONCEPT PROTOTYPES (what each class means)\n",
        "STAGE 2: Train on CSV data WITH concept similarity features\n",
        "RESULT:  Model has semantic understanding + learns from labeled data\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFGAHed_DY-F"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -U -q setfit huggingface_hub transformers datasets sentence-transformers\n",
        "!pip install -q sentence-transformers>=2.2.0\n",
        "!pip install -q datasets torch\n",
        "!pip install -q scikit-learn pandas numpy matplotlib seaborn tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gN2Zp-vQDY-G"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import re\n",
        "import random\n",
        "from typing import List, Dict, Tuple\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from setfit import SetFitModel, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Device: {DEVICE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWHrjS5rDY-G"
      },
      "source": [
        "## 1. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMITCclkDY-H"
      },
      "outputs": [],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"LOADING DATA - ZERO LEAKAGE SETUP\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# TRAINING DATA - CSVs only\n",
        "df_dept_csv = pd.read_csv('department-v2.csv')[['text', 'label']].dropna()\n",
        "df_sen_csv = pd.read_csv('seniority-v2.csv')[['text', 'label']].dropna()\n",
        "\n",
        "# TEST DATA - 100% held out\n",
        "with open('testdata.txt', 'r', encoding='utf-8') as f:\n",
        "    test_cvs = json.load(f)\n",
        "df_test = pd.DataFrame([j for cv in test_cvs for j in cv if j.get('status') == 'ACTIVE'])\n",
        "\n",
        "# PRODUCTION DATA\n",
        "with open('more.txt', 'r', encoding='utf-8') as f:\n",
        "    more_cvs = json.load(f)\n",
        "df_prod = pd.DataFrame([j for cv in more_cvs for j in cv if j.get('status') == 'ACTIVE'])\n",
        "\n",
        "print(f\"TRAINING CSVs: {len(df_sen_csv)} seniority + {len(df_dept_csv)} department\")\n",
        "print(f\"TESTING (100% held out): {len(df_test)} samples\")\n",
        "print(f\"PRODUCTION: {len(df_prod)} samples\")\n",
        "print(\"\\n⚠️  testdata.txt is NEVER used for training!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5EhnmFWDY-H"
      },
      "source": [
        "---\n",
        "# STAGE 1: Learn Concept Prototypes\n",
        "---\n",
        "\n",
        "The model first learns what each class MEANS by encoding rich concept descriptions.\n",
        "These become **fixed semantic anchors** that define each class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3pqHvggDY-H"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"STAGE 1: CONCEPT KNOWLEDGE BASE\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# =============================================================================\n",
        "# SENIORITY CONCEPTS - Rich descriptions of what each level MEANS\n",
        "# =============================================================================\n",
        "# CRITICAL FIXES based on test data analysis:\n",
        "# - Professional = DEFAULT, includes Product/Project Manager (manages products, not people)\n",
        "# - Lead = ONLY team/people leadership (Head of, Leiter, Team Lead)\n",
        "# - Management = C-level + Owners + Founders (business owners)\n",
        "# =============================================================================\n",
        "\n",
        "SENIORITY_CONCEPTS = {\n",
        "    'Management': \"\"\"\n",
        "        C-level executives and business owners who run companies.\n",
        "        CEO, Chief Executive Officer, CFO, Chief Financial Officer, COO, Chief Operating Officer,\n",
        "        CMO, Chief Marketing Officer, CRO, Chief Revenue Officer, CIO, CHRO, CTO,\n",
        "        Managing Director, General Manager, President, Vice President of company,\n",
        "        Owner, Co-Owner, Founder, Co-Founder, Partner, Board Member, Shareholder, Investor,\n",
        "        Geschäftsführer, Geschäftsführerin, Vorstand, Vorstandsvorsitzender,\n",
        "        Inhaber, Inhaberin, Gründer, Mitgründer, Gesellschafter, Prokurist,\n",
        "        PDG, Directeur Général, Gérant, Fondateur, Propriétaire,\n",
        "        Administrerende Direktør, VD, Verkställande Direktör\n",
        "    \"\"\",\n",
        "\n",
        "    'Director': \"\"\"\n",
        "        Directors of specific functions or departments, but not company-wide executives.\n",
        "        Director of Sales, Director of Marketing, Director of Engineering,\n",
        "        Director of HR, Director of Finance, Director of Operations, Director of Product,\n",
        "        Sales Director, Marketing Director, Finance Director, Technical Director,\n",
        "        Creative Director, Commercial Director, Regional Director, Executive Director,\n",
        "        Senior Director, Associate Director,\n",
        "        Vertriebsdirektor, Marketingdirektor, Finanzdirektor,\n",
        "        Directeur Commercial, Directeur Marketing, Directeur Financier,\n",
        "        Note: Managing Director is Management level, not Director\n",
        "    \"\"\",\n",
        "\n",
        "    'Lead': \"\"\"\n",
        "        Team leaders and department heads who manage PEOPLE and teams directly.\n",
        "        Head of Engineering, Head of Sales, Head of Marketing, Head of HR, Head of Product,\n",
        "        Team Lead, Tech Lead, Team Leader, Engineering Lead, Design Lead,\n",
        "        Leiter, Leiterin, Abteilungsleiter, Bereichsleiter, Teamleiter, Teamleiterin,\n",
        "        Kaufmännischer Leiter, Technischer Leiter, Personalleiter, Vertriebsleiter, IT-Leiter,\n",
        "        Gruppenleiter, Filialleiter, Betriebsleiter, Supervisor,\n",
        "        Chef de Service, Chef d'Équipe, Responsable d'équipe,\n",
        "        Note: Product Manager and Project Manager are Professional, not Lead (they manage products/projects, not people)\n",
        "    \"\"\",\n",
        "\n",
        "    'Senior': \"\"\"\n",
        "        Experienced professionals with explicit senior designation in their title.\n",
        "        MUST have Senior, Sr., Principal, Staff, or Expert keyword.\n",
        "        Senior Software Engineer, Senior Developer, Senior Analyst, Senior Consultant,\n",
        "        Senior Manager, Senior Designer, Senior Architect, Senior Project Manager,\n",
        "        Senior Data Scientist, Senior Account Manager, Senior Product Manager,\n",
        "        Sr. Software Engineer, Sr. Developer, Sr. Consultant,\n",
        "        Principal Engineer, Principal Consultant, Principal Architect,\n",
        "        Staff Engineer, Staff Software Engineer,\n",
        "        Expert, Experte, Fachexperte, Senior Entwickler, Senior Berater,\n",
        "        Ingénieur Senior, Consultant Senior\n",
        "    \"\"\",\n",
        "\n",
        "    'Professional': \"\"\"\n",
        "        Standard professional roles without senior/junior designation. This is the DEFAULT level.\n",
        "        Software Engineer, Developer, Programmer, Data Scientist, Data Analyst,\n",
        "        Product Manager, Project Manager, Program Manager (manage products/projects, not people),\n",
        "        Marketing Manager, HR Manager, Sales Manager, Account Manager, Brand Manager,\n",
        "        Business Development Manager, Purchasing Manager, Operations Manager,\n",
        "        Consultant, Analyst, Business Analyst, Designer, Architect, Solutions Architect,\n",
        "        Engineer, Researcher, Specialist, Coordinator, Referent, Sachbearbeiter,\n",
        "        Entwickler, Programmierer, Berater, Ingenieur,\n",
        "        Physician Assistant, Executive Assistant, Reporter, Coach, Trainer,\n",
        "        Développeur, Analyste, Ingénieur, Chef de Projet, Projektmanager, Produktmanager\n",
        "    \"\"\",\n",
        "\n",
        "    'Junior': \"\"\"\n",
        "        Entry-level roles, interns, trainees, and apprentices.\n",
        "        Junior Developer, Junior Software Engineer, Junior Analyst, Junior Consultant,\n",
        "        Junior Designer, Junior Accountant, Junior Project Manager,\n",
        "        Intern, Trainee, Apprentice, Working Student, Graduate, Entry Level,\n",
        "        Praktikant, Praktikantin, Werkstudent, Werkstudentin,\n",
        "        Azubi, Auszubildender, Auszubildende, Volontär, Berufseinsteiger,\n",
        "        Stagiaire, Alternant, Apprenti,\n",
        "        Practicante, Becario, PhD Student, Research Assistant\n",
        "    \"\"\"\n",
        "}\n",
        "\n",
        "print(\"Seniority Concepts Loaded:\")\n",
        "for k in SENIORITY_CONCEPTS:\n",
        "    print(f\"  - {k}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7CAW1b8DY-I"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# DEPARTMENT CONCEPTS\n",
        "# =============================================================================\n",
        "# CRITICAL FIXES:\n",
        "# - Other = CEO, CFO, Finance, Legal, Medical, Education, General executives\n",
        "# - IT = includes CTO\n",
        "# - Project Management = includes Product Manager\n",
        "# =============================================================================\n",
        "\n",
        "DEPARTMENT_CONCEPTS = {\n",
        "    'Information Technology': \"\"\"\n",
        "        Software development, IT infrastructure, data, and technology roles.\n",
        "        Software Engineer, Developer, Programmer, Full Stack Developer,\n",
        "        Backend Developer, Frontend Developer, Web Developer, Mobile Developer,\n",
        "        Data Scientist, Data Engineer, Data Analyst, Machine Learning Engineer, AI Engineer,\n",
        "        DevOps Engineer, Cloud Engineer, System Administrator, Network Engineer,\n",
        "        Solutions Architect, Enterprise Architect, Technical Architect,\n",
        "        IT Manager, IT Director, CTO, Chief Technology Officer, VP of Engineering,\n",
        "        QA Engineer, Test Engineer, Security Engineer, Cyber Security,\n",
        "        Softwareentwickler, Entwickler, Programmierer, Informatiker,\n",
        "        Développeur, Ingénieur Logiciel, Tech Lead\n",
        "    \"\"\",\n",
        "\n",
        "    'Sales': \"\"\"\n",
        "        Sales, revenue generation, and account management roles.\n",
        "        Sales Representative, Account Executive, Sales Manager, Sales Director,\n",
        "        Key Account Manager, Inside Sales, Outside Sales, Sales Engineer,\n",
        "        Territory Manager, Regional Sales Manager, VP of Sales, Head of Sales,\n",
        "        Account Manager, Business Development Representative,\n",
        "        Vertriebsmitarbeiter, Verkäufer, Außendienstmitarbeiter, Vertriebsleiter,\n",
        "        Commercial, Vendeur, Attaché Commercial, Vertrieb\n",
        "    \"\"\",\n",
        "\n",
        "    'Marketing': \"\"\"\n",
        "        Marketing, branding, communications, and content roles.\n",
        "        Marketing Manager, Brand Manager, Digital Marketing Manager, Content Manager,\n",
        "        Social Media Manager, SEO Specialist, Marketing Analyst, Marketing Director,\n",
        "        Growth Manager, Product Marketing Manager, PR Manager, Communications Manager,\n",
        "        CMO, Chief Marketing Officer, Head of Marketing,\n",
        "        Marketingleiter, Online Marketing Manager,\n",
        "        Responsable Marketing, Chef de Produit Marketing\n",
        "    \"\"\",\n",
        "\n",
        "    'Human Resources': \"\"\"\n",
        "        HR, recruiting, talent management, and people operations.\n",
        "        HR Manager, Recruiter, Talent Acquisition Specialist, HR Business Partner,\n",
        "        CHRO, HR Director, People Operations Manager, HR Generalist,\n",
        "        Learning and Development Manager, Compensation and Benefits,\n",
        "        Personalleiter, Personalreferent, Personalsachbearbeiter,\n",
        "        Responsable RH, DRH, Chargé de Recrutement\n",
        "    \"\"\",\n",
        "\n",
        "    'Consulting': \"\"\"\n",
        "        Advisory and consulting services roles.\n",
        "        Consultant, Management Consultant, Strategy Consultant, Business Consultant,\n",
        "        Senior Consultant, Principal Consultant, Associate Consultant,\n",
        "        IT Consultant, Technology Consultant, Digital Consultant,\n",
        "        Berater, Unternehmensberater, Managementberater,\n",
        "        Conseiller, Consultant en stratégie\n",
        "    \"\"\",\n",
        "\n",
        "    'Project Management': \"\"\"\n",
        "        Project, product, and program management roles.\n",
        "        Project Manager, Projektmanager, Senior Project Manager, Program Manager,\n",
        "        Product Manager, Produktmanager, Product Owner, Associate Product Manager,\n",
        "        PMO Manager, Scrum Master, Agile Coach, Delivery Manager,\n",
        "        Project Coordinator, Projektkoordinator, Projektleiter,\n",
        "        Technical Program Manager, Portfolio Manager,\n",
        "        Chef de Projet, Gerente de Proyecto\n",
        "    \"\"\",\n",
        "\n",
        "    'Business Development': \"\"\"\n",
        "        Business development and strategic partnership roles.\n",
        "        Business Development Manager, Partnership Manager, Strategic Partnerships,\n",
        "        Corporate Development, M&A Manager, Alliance Manager,\n",
        "        Business Development Representative, BD Manager,\n",
        "        Geschäftsentwicklung, Partnermanager\n",
        "    \"\"\",\n",
        "\n",
        "    'Customer Support': \"\"\"\n",
        "        Customer service, support, and success roles.\n",
        "        Customer Service Representative, Support Engineer, Customer Success Manager,\n",
        "        Help Desk Technician, Technical Support Specialist, Customer Care,\n",
        "        Service Desk Analyst, Support Analyst,\n",
        "        Kundenberater, Kundenbetreuer, Kundenservice,\n",
        "        Chargé de Clientèle, Service Client\n",
        "    \"\"\",\n",
        "\n",
        "    'Administrative': \"\"\"\n",
        "        Office administration and assistant roles.\n",
        "        Office Manager, Executive Assistant, Administrative Assistant, Secretary,\n",
        "        Receptionist, Office Administrator, Personal Assistant, Office Coordinator,\n",
        "        Assistent, Assistentin, Sekretär, Sekretärin, Empfang,\n",
        "        Bürokauffrau, Bürokaufmann, Verwaltungsangestellter,\n",
        "        Secrétaire, Réceptionniste, Assistant de Direction\n",
        "    \"\"\",\n",
        "\n",
        "    'Purchasing': \"\"\"\n",
        "        Procurement, purchasing, and supply chain roles.\n",
        "        Purchasing Manager, Procurement Specialist, Buyer, Strategic Buyer,\n",
        "        Sourcing Manager, Supply Chain Manager, Vendor Manager, Category Manager,\n",
        "        Einkäufer, Einkaufsleiter, Beschaffungsmanager,\n",
        "        Acheteur, Responsable Achats\n",
        "    \"\"\",\n",
        "\n",
        "    'Other': \"\"\"\n",
        "        Executive leadership, finance, legal, medical, education, and other specialized roles.\n",
        "        CEO, CFO, COO, CRO, Managing Director, President, General Manager,\n",
        "        Founder, Co-Founder, Owner, Entrepreneur, Investor, Board Member,\n",
        "        Geschäftsführer, Inhaber, Vorstand, Prokurist, Gesellschafter,\n",
        "        Accountant, Controller, Financial Analyst, Finance Manager, Treasurer, Buchhalter,\n",
        "        Lawyer, Legal Counsel, Attorney, Rechtsanwalt, Jurist, Avocat,\n",
        "        Doctor, Physician, Arzt, Médecin, Nurse, Pharmacist,\n",
        "        Professor, Teacher, Lecturer, Trainer, Coach, Dozent,\n",
        "        Researcher, Scientist, Forscher, Research Associate,\n",
        "        Operations Manager, Quality Manager, Compliance Officer,\n",
        "        Journalist, Reporter, Editor, Writer,\n",
        "        Freelancer, Self-employed, Selbständig,\n",
        "        Waiter, Chef, Bartender, Artist, Musician\n",
        "    \"\"\"\n",
        "}\n",
        "\n",
        "print(\"\\nDepartment Concepts Loaded:\")\n",
        "for k in DEPARTMENT_CONCEPTS:\n",
        "    print(f\"  - {k}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YOe_OZvDY-J"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"ENCODING CONCEPT PROTOTYPES\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Load the encoder model\n",
        "MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
        "encoder = SentenceTransformer(MODEL_NAME, device=DEVICE)\n",
        "\n",
        "print(f\"Model: {MODEL_NAME}\")\n",
        "print(f\"Embedding dimension: {encoder.get_sentence_embedding_dimension()}\")\n",
        "\n",
        "def encode_concept(concept_text):\n",
        "    \"\"\"Encode a concept description into a prototype embedding.\"\"\"\n",
        "    # Clean the text\n",
        "    clean = ' '.join(concept_text.split())\n",
        "    # Encode with normalization for cosine similarity\n",
        "    embedding = encoder.encode(clean, normalize_embeddings=True)\n",
        "    return embedding\n",
        "\n",
        "# Encode all concepts - these become our CLASS PROTOTYPES\n",
        "print(\"\\nEncoding seniority prototypes...\")\n",
        "SEN_LABELS = list(SENIORITY_CONCEPTS.keys())\n",
        "sen_prototypes = np.stack([encode_concept(SENIORITY_CONCEPTS[l]) for l in SEN_LABELS])\n",
        "print(f\"  Shape: {sen_prototypes.shape}\")\n",
        "\n",
        "print(\"Encoding department prototypes...\")\n",
        "DEPT_LABELS = list(DEPARTMENT_CONCEPTS.keys())\n",
        "dept_prototypes = np.stack([encode_concept(DEPARTMENT_CONCEPTS[l]) for l in DEPT_LABELS])\n",
        "print(f\"  Shape: {dept_prototypes.shape}\")\n",
        "\n",
        "print(\"\\n✓ Concept prototypes created!\")\n",
        "print(\"  These embeddings capture the MEANING of each class.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eRq_DN0DY-K"
      },
      "outputs": [],
      "source": [
        "# Verify concept prototypes work with simple similarity test\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"VERIFYING CONCEPT PROTOTYPES\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "test_titles = [\n",
        "    \"CEO\",\n",
        "    \"Senior Software Engineer\",\n",
        "    \"Praktikant\",\n",
        "    \"Projektmanager\",\n",
        "    \"Head of Sales\",\n",
        "    \"Geschäftsführer\",\n",
        "    \"Product Manager\"\n",
        "]\n",
        "\n",
        "# Encode test titles\n",
        "test_embs = encoder.encode(test_titles, normalize_embeddings=True)\n",
        "\n",
        "# Compute similarities to seniority prototypes\n",
        "sen_sims = np.dot(test_embs, sen_prototypes.T)\n",
        "\n",
        "print(\"\\nSeniority Concept Similarity Test:\")\n",
        "print(f\"{'Title':<30} \" + \" \".join([f\"{l[:8]:>10}\" for l in SEN_LABELS]) + \"  → Prediction\")\n",
        "print(\"-\" * 110)\n",
        "for i, title in enumerate(test_titles):\n",
        "    sims_str = \" \".join([f\"{s:>10.3f}\" for s in sen_sims[i]])\n",
        "    pred = SEN_LABELS[np.argmax(sen_sims[i])]\n",
        "    print(f\"{title:<30} {sims_str}  → {pred}\")\n",
        "\n",
        "# Compute similarities to department prototypes\n",
        "dept_sims = np.dot(test_embs, dept_prototypes.T)\n",
        "\n",
        "print(\"\\nDepartment Concept Similarity Test:\")\n",
        "print(f\"{'Title':<30} → Prediction (Top Similarity)\")\n",
        "print(\"-\" * 60)\n",
        "for i, title in enumerate(test_titles):\n",
        "    pred_idx = np.argmax(dept_sims[i])\n",
        "    pred = DEPT_LABELS[pred_idx]\n",
        "    conf = dept_sims[i][pred_idx]\n",
        "    print(f\"{title:<30} → {pred:<25} ({conf:.3f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJVSFuFDDY-K"
      },
      "source": [
        "---\n",
        "# STAGE 2: Train with Concept-Enhanced Features\n",
        "---\n",
        "\n",
        "Now we train on CSV data, but each training example gets **concept similarity features** appended.\n",
        "This gives the model both:\n",
        "1. The raw semantic embedding of the title\n",
        "2. Pre-computed similarity to each concept prototype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nc0xWqmzDY-K"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"STAGE 2: PREPARE CONCEPT-ENHANCED TRAINING DATA\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "def clean_text(text):\n",
        "    if pd.isna(text) or not text:\n",
        "        return \"\"\n",
        "    return ' '.join(str(text).split())\n",
        "\n",
        "def compute_concept_features(texts, prototypes, encoder):\n",
        "    \"\"\"\n",
        "    For each text, compute:\n",
        "    1. Raw embedding (384d)\n",
        "    2. Similarity to each concept prototype (n_concepts)\n",
        "\n",
        "    Returns: embeddings, similarities\n",
        "    \"\"\"\n",
        "    # Encode texts\n",
        "    embeddings = encoder.encode(texts, normalize_embeddings=True, show_progress_bar=True)\n",
        "\n",
        "    # Compute cosine similarity to each prototype\n",
        "    similarities = np.dot(embeddings, prototypes.T)\n",
        "\n",
        "    return embeddings, similarities\n",
        "\n",
        "print(\"Function defined: compute_concept_features()\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyJ47RrVDY-L"
      },
      "outputs": [],
      "source": [
        "# Prepare CSV training data\n",
        "print(\"\\nPreparing training data from CSVs...\")\n",
        "\n",
        "# Clean texts\n",
        "df_sen_csv['text_clean'] = df_sen_csv['text'].apply(clean_text)\n",
        "df_dept_csv['text_clean'] = df_dept_csv['text'].apply(clean_text)\n",
        "\n",
        "# Remove empty\n",
        "df_sen_csv = df_sen_csv[df_sen_csv['text_clean'].str.len() > 0].copy()\n",
        "df_dept_csv = df_dept_csv[df_dept_csv['text_clean'].str.len() > 0].copy()\n",
        "\n",
        "# Balance by downsampling majority classes\n",
        "def balanced_sample(df, label_col, max_per_class=300):\n",
        "    sampled = []\n",
        "    for label in df[label_col].unique():\n",
        "        label_df = df[df[label_col] == label]\n",
        "        n = min(len(label_df), max_per_class)\n",
        "        sampled.append(label_df.sample(n=n, random_state=SEED))\n",
        "    return pd.concat(sampled, ignore_index=True)\n",
        "\n",
        "df_sen_train = balanced_sample(df_sen_csv, 'label', max_per_class=300)\n",
        "df_dept_train = balanced_sample(df_dept_csv, 'label', max_per_class=300)\n",
        "\n",
        "print(f\"\\nSeniority training: {len(df_sen_train)} samples\")\n",
        "print(df_sen_train['label'].value_counts())\n",
        "print(f\"\\nDepartment training: {len(df_dept_train)} samples\")\n",
        "print(df_dept_train['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYmr22D2DY-L"
      },
      "outputs": [],
      "source": [
        "# Compute concept-enhanced features for training data\n",
        "print(\"\\nComputing concept-enhanced features for training data...\")\n",
        "\n",
        "# Seniority\n",
        "sen_train_texts = df_sen_train['text_clean'].tolist()\n",
        "sen_train_embs, sen_train_concept_sims = compute_concept_features(\n",
        "    sen_train_texts, sen_prototypes, encoder\n",
        ")\n",
        "\n",
        "# Department\n",
        "dept_train_texts = df_dept_train['text_clean'].tolist()\n",
        "dept_train_embs, dept_train_concept_sims = compute_concept_features(\n",
        "    dept_train_texts, dept_prototypes, encoder\n",
        ")\n",
        "\n",
        "print(f\"\\nSeniority features:\")\n",
        "print(f\"  Embeddings: {sen_train_embs.shape}\")\n",
        "print(f\"  Concept similarities: {sen_train_concept_sims.shape}\")\n",
        "\n",
        "print(f\"\\nDepartment features:\")\n",
        "print(f\"  Embeddings: {dept_train_embs.shape}\")\n",
        "print(f\"  Concept similarities: {dept_train_concept_sims.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHCGEhIyDY-L"
      },
      "outputs": [],
      "source": [
        "# Create enhanced feature vectors: [embedding | concept_similarities]\n",
        "print(\"\\nCreating enhanced feature vectors...\")\n",
        "\n",
        "# Concatenate: [384d embedding] + [6d or 11d concept similarities]\n",
        "sen_train_enhanced = np.concatenate([sen_train_embs, sen_train_concept_sims], axis=1)\n",
        "dept_train_enhanced = np.concatenate([dept_train_embs, dept_train_concept_sims], axis=1)\n",
        "\n",
        "print(f\"Seniority enhanced: {sen_train_enhanced.shape}\")\n",
        "print(f\"  = {sen_train_embs.shape[1]} (embedding) + {sen_train_concept_sims.shape[1]} (concept sims)\")\n",
        "\n",
        "print(f\"\\nDepartment enhanced: {dept_train_enhanced.shape}\")\n",
        "print(f\"  = {dept_train_embs.shape[1]} (embedding) + {dept_train_concept_sims.shape[1]} (concept sims)\")\n",
        "\n",
        "# Encode labels\n",
        "sen_label_encoder = LabelEncoder()\n",
        "sen_train_labels = sen_label_encoder.fit_transform(df_sen_train['label'])\n",
        "\n",
        "dept_label_encoder = LabelEncoder()\n",
        "dept_train_labels = dept_label_encoder.fit_transform(df_dept_train['label'])\n",
        "\n",
        "print(f\"\\nSeniority labels: {sen_label_encoder.classes_}\")\n",
        "print(f\"Department labels: {dept_label_encoder.classes_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDeKyV2GDY-L"
      },
      "source": [
        "## 3. Train Concept-Aware Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ci-xXy9DY-L"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"TRAINING CONCEPT-AWARE CLASSIFIERS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# We'll train TWO types of classifiers:\n",
        "# 1. MLP on enhanced features (embedding + concept similarities)\n",
        "# 2. SetFit for contrastive learning\n",
        "\n",
        "print(\"\\n--- Training Seniority MLP ---\")\n",
        "sen_mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=(256, 128),\n",
        "    activation='relu',\n",
        "    max_iter=500,\n",
        "    random_state=SEED,\n",
        "    early_stopping=True,\n",
        "    validation_fraction=0.1,\n",
        "    n_iter_no_change=20\n",
        ")\n",
        "sen_mlp.fit(sen_train_enhanced, sen_train_labels)\n",
        "print(f\"✓ Seniority MLP trained (best validation score: {sen_mlp.best_validation_score_:.3f})\")\n",
        "\n",
        "print(\"\\n--- Training Department MLP ---\")\n",
        "dept_mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=(256, 128),\n",
        "    activation='relu',\n",
        "    max_iter=500,\n",
        "    random_state=SEED,\n",
        "    early_stopping=True,\n",
        "    validation_fraction=0.1,\n",
        "    n_iter_no_change=20\n",
        ")\n",
        "dept_mlp.fit(dept_train_enhanced, dept_train_labels)\n",
        "print(f\"✓ Department MLP trained (best validation score: {dept_mlp.best_validation_score_:.3f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qt8cwOBoDY-M"
      },
      "outputs": [],
      "source": [
        "# Also train SetFit models for ensemble\n",
        "print(\"\\n--- Training SetFit Models (for ensemble) ---\")\n",
        "\n",
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "\n",
        "# SetFit Seniority\n",
        "train_sen_ds = Dataset.from_pandas(df_sen_train[['text_clean', 'label']].rename(columns={'text_clean': 'text'}))\n",
        "\n",
        "sen_setfit = SetFitModel.from_pretrained(MODEL_NAME, labels=list(sen_label_encoder.classes_))\n",
        "sen_setfit_args = TrainingArguments(\n",
        "    batch_size=128,\n",
        "    num_epochs=1,\n",
        "    num_iterations=20,\n",
        "    body_learning_rate=1e-5,\n",
        "    head_learning_rate=1e-2,\n",
        "    seed=SEED,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "sen_setfit_trainer = Trainer(\n",
        "    model=sen_setfit,\n",
        "    args=sen_setfit_args,\n",
        "    train_dataset=train_sen_ds,\n",
        "    column_mapping={\"text\": \"text\", \"label\": \"label\"}\n",
        ")\n",
        "sen_setfit_trainer.train()\n",
        "print(\"✓ Seniority SetFit trained\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vrk_O_P-DY-M"
      },
      "outputs": [],
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "\n",
        "# SetFit Department\n",
        "train_dept_ds = Dataset.from_pandas(df_dept_train[['text_clean', 'label']].rename(columns={'text_clean': 'text'}))\n",
        "\n",
        "dept_setfit = SetFitModel.from_pretrained(MODEL_NAME, labels=list(dept_label_encoder.classes_))\n",
        "dept_setfit_args = TrainingArguments(\n",
        "    batch_size=128,\n",
        "    num_epochs=1,\n",
        "    num_iterations=20,\n",
        "    body_learning_rate=1e-5,\n",
        "    head_learning_rate=1e-2,\n",
        "    seed=SEED,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "dept_setfit_trainer = Trainer(\n",
        "    model=dept_setfit,\n",
        "    args=dept_setfit_args,\n",
        "    train_dataset=train_dept_ds,\n",
        "    column_mapping={\"text\": \"text\", \"label\": \"label\"}\n",
        ")\n",
        "dept_setfit_trainer.train()\n",
        "print(\"✓ Department SetFit trained\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmbXYhUpDY-M"
      },
      "source": [
        "## 4. Ensemble Prediction Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIqifo4eDY-M"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"CREATING ENSEMBLE PREDICTOR\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "def predict_ensemble(\n",
        "    texts,\n",
        "    mlp_model,\n",
        "    setfit_model,\n",
        "    prototypes,              # (n_proto_classes, emb_dim)\n",
        "    label_encoder,\n",
        "    encoder,\n",
        "    mlp_weight=0.4,\n",
        "    setfit_weight=0.3,\n",
        "    concept_weight=0.3,\n",
        "):\n",
        "    \"\"\"\n",
        "    Ensemble prediction combining:\n",
        "    1. MLP on concept-enhanced features\n",
        "    2. SetFit contrastive model\n",
        "    3. Direct concept similarity\n",
        "    \"\"\"\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Canonical label space\n",
        "    # ------------------------------------------------------------------\n",
        "    labels = list(label_encoder.classes_)\n",
        "    n_classes = len(labels)\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Embeddings\n",
        "    # ------------------------------------------------------------------\n",
        "    embeddings = encoder.encode(\n",
        "        texts, normalize_embeddings=True, show_progress_bar=False\n",
        "    )\n",
        "    emb_dim = embeddings.shape[1]\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # ----- CONCEPT PROTOTYPE ALIGNMENT + PADDING (CRITICAL FIX) -----\n",
        "    # ------------------------------------------------------------------\n",
        "    proto_dim = prototypes.shape[1]\n",
        "    proto_count = prototypes.shape[0]\n",
        "\n",
        "    # Aligned concepts (canonical labels)\n",
        "    aligned_prototypes = np.zeros((n_classes, proto_dim))\n",
        "    for i in range(min(n_classes, proto_count)):\n",
        "        aligned_prototypes[i] = prototypes[i]\n",
        "\n",
        "    concept_sims_aligned = np.dot(embeddings, aligned_prototypes.T)\n",
        "    # shape: (N, n_classes)\n",
        "\n",
        "    # ---- PAD concept features back to MLP expected size ----\n",
        "    expected_features = mlp_model.n_features_in_\n",
        "    expected_concept_dim = expected_features - emb_dim\n",
        "\n",
        "    if concept_sims_aligned.shape[1] < expected_concept_dim:\n",
        "        pad_width = expected_concept_dim - concept_sims_aligned.shape[1]\n",
        "        concept_sims = np.concatenate(\n",
        "            [concept_sims_aligned, np.zeros((len(texts), pad_width))],\n",
        "            axis=1,\n",
        "        )\n",
        "    else:\n",
        "        concept_sims = concept_sims_aligned\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # 1. MLP predictions (now feature-compatible)\n",
        "    # ------------------------------------------------------------------\n",
        "    enhanced_features = np.concatenate([embeddings, concept_sims], axis=1)\n",
        "    mlp_probs = mlp_model.predict_proba(enhanced_features)\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # 2. SetFit predictions (aligned)\n",
        "    # ------------------------------------------------------------------\n",
        "    setfit_probs_raw = np.array(setfit_model.predict_proba(texts))\n",
        "    setfit_labels = list(setfit_model.labels)\n",
        "\n",
        "    setfit_probs_aligned = np.zeros((len(texts), n_classes))\n",
        "    for i, lbl in enumerate(labels):\n",
        "        if lbl in setfit_labels:\n",
        "            j = setfit_labels.index(lbl)\n",
        "            setfit_probs_aligned[:, i] = setfit_probs_raw[:, j]\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # 3. Concept similarity → probabilities (canonical only)\n",
        "    # ------------------------------------------------------------------\n",
        "    temperature = 3.0\n",
        "    exp_sims = np.exp(concept_sims_aligned * temperature)\n",
        "    concept_probs = exp_sims / exp_sims.sum(axis=1, keepdims=True)\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Safety check\n",
        "    # ------------------------------------------------------------------\n",
        "    assert (\n",
        "        mlp_probs.shape\n",
        "        == setfit_probs_aligned.shape\n",
        "        == concept_probs.shape\n",
        "    ), (\n",
        "        mlp_probs.shape,\n",
        "        setfit_probs_aligned.shape,\n",
        "        concept_probs.shape,\n",
        "    )\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Ensemble\n",
        "    # ------------------------------------------------------------------\n",
        "    combined_probs = (\n",
        "        mlp_weight * mlp_probs\n",
        "        + setfit_weight * setfit_probs_aligned\n",
        "        + concept_weight * concept_probs\n",
        "    )\n",
        "\n",
        "    predictions = []\n",
        "    confidences = []\n",
        "\n",
        "    for i in range(len(texts)):\n",
        "        idx = np.argmax(combined_probs[i])\n",
        "        predictions.append(labels[idx])\n",
        "        confidences.append(float(combined_probs[i, idx]))\n",
        "\n",
        "    return predictions, confidences\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# Test\n",
        "# ----------------------------------------------------------------------\n",
        "test_titles = [\n",
        "    \"Senior Software Engineer\",\n",
        "    \"CEO\",\n",
        "    \"Praktikant\",\n",
        "    \"Projektmanager\",\n",
        "    \"Head of Sales\",\n",
        "]\n",
        "\n",
        "preds, confs = predict_ensemble(\n",
        "    test_titles,\n",
        "    sen_mlp,\n",
        "    sen_setfit,\n",
        "    sen_prototypes,\n",
        "    sen_label_encoder,\n",
        "    encoder,\n",
        ")\n",
        "\n",
        "print(\"\\nTest Predictions (Seniority):\")\n",
        "for t, p, c in zip(test_titles, preds, confs):\n",
        "    print(f\"  {t:<30} → {p:<15} (conf: {c:.3f})\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gzuWT78DY-N"
      },
      "source": [
        "## 5. Evaluate on HELD-OUT Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByQCWE4TDY-N"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"EVALUATION ON 100% HELD-OUT TEST DATA\")\n",
        "print(\"=\" * 70)\n",
        "print(\"⚠️  This data was NEVER seen during training!\\n\")\n",
        "\n",
        "# Prepare test data\n",
        "df_test['text_clean'] = df_test['position'].apply(clean_text)\n",
        "test_texts = df_test['text_clean'].tolist()\n",
        "\n",
        "print(f\"Evaluating on {len(test_texts)} samples...\\n\")\n",
        "\n",
        "# Seniority predictions\n",
        "print(\"Predicting seniority...\")\n",
        "sen_preds, sen_confs = predict_ensemble(\n",
        "    test_texts, sen_mlp, sen_setfit, sen_prototypes, sen_label_encoder, encoder\n",
        ")\n",
        "df_test['pred_sen'] = sen_preds\n",
        "df_test['sen_conf'] = sen_confs\n",
        "\n",
        "# Department predictions\n",
        "print(\"Predicting department...\")\n",
        "dept_preds, dept_confs = predict_ensemble(\n",
        "    test_texts, dept_mlp, dept_setfit, dept_prototypes, dept_label_encoder, encoder\n",
        ")\n",
        "df_test['pred_dept'] = dept_preds\n",
        "df_test['dept_conf'] = dept_confs\n",
        "\n",
        "print(\"\\n✓ Predictions complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEC6gRQuDY-N"
      },
      "outputs": [],
      "source": [
        "# Calculate metrics\n",
        "sen_acc = accuracy_score(df_test['seniority'], df_test['pred_sen'])\n",
        "sen_f1 = f1_score(df_test['seniority'], df_test['pred_sen'], average='macro', zero_division=0)\n",
        "sen_f1_w = f1_score(df_test['seniority'], df_test['pred_sen'], average='weighted', zero_division=0)\n",
        "\n",
        "dept_acc = accuracy_score(df_test['department'], df_test['pred_dept'])\n",
        "dept_f1 = f1_score(df_test['department'], df_test['pred_dept'], average='macro', zero_division=0)\n",
        "dept_f1_w = f1_score(df_test['department'], df_test['pred_dept'], average='weighted', zero_division=0)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"FINAL RESULTS (on 100% held-out testdata.txt)\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\n{'Metric':<25} {'Seniority':>15} {'Department':>15}\")\n",
        "print(\"-\" * 55)\n",
        "print(f\"{'Accuracy':<25} {sen_acc*100:>14.2f}% {dept_acc*100:>14.2f}%\")\n",
        "print(f\"{'F1 (Macro)':<25} {sen_f1:>15.3f} {dept_f1:>15.3f}\")\n",
        "print(f\"{'F1 (Weighted)':<25} {sen_f1_w:>15.3f} {dept_f1_w:>15.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nM5gPAMEDY-N"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"SENIORITY CLASSIFICATION REPORT\")\n",
        "print(\"=\" * 70)\n",
        "print(classification_report(df_test['seniority'], df_test['pred_sen'], zero_division=0))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"DEPARTMENT CLASSIFICATION REPORT\")\n",
        "print(\"=\" * 70)\n",
        "print(classification_report(df_test['department'], df_test['pred_dept'], zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_U1m3zXLDY-N"
      },
      "outputs": [],
      "source": [
        "# Confusion matrices\n",
        "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
        "\n",
        "# Seniority\n",
        "sen_labels_sorted = sorted(set(df_test['seniority']) | set(df_test['pred_sen']))\n",
        "cm_sen = confusion_matrix(df_test['seniority'], df_test['pred_sen'], labels=sen_labels_sorted)\n",
        "sns.heatmap(cm_sen, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=sen_labels_sorted, yticklabels=sen_labels_sorted, ax=axes[0])\n",
        "axes[0].set_title(f'Seniority ({sen_acc*100:.1f}%)', fontweight='bold')\n",
        "axes[0].set_xlabel('Predicted')\n",
        "axes[0].set_ylabel('Actual')\n",
        "plt.setp(axes[0].xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
        "\n",
        "# Department\n",
        "dept_labels_sorted = sorted(set(df_test['department']) | set(df_test['pred_dept']))\n",
        "cm_dept = confusion_matrix(df_test['department'], df_test['pred_dept'], labels=dept_labels_sorted)\n",
        "sns.heatmap(cm_dept, annot=True, fmt='d', cmap='Oranges',\n",
        "            xticklabels=dept_labels_sorted, yticklabels=dept_labels_sorted, ax=axes[1])\n",
        "axes[1].set_title(f'Department ({dept_acc*100:.1f}%)', fontweight='bold')\n",
        "axes[1].set_xlabel('Predicted')\n",
        "axes[1].set_ylabel('Actual')\n",
        "plt.setp(axes[1].xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('confusion_setfit_v3_concept.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCcCFT5nDY-N"
      },
      "source": [
        "## 6. Error Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PtJHdbvDY-N"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"ERROR ANALYSIS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Seniority errors\n",
        "sen_errors = df_test[df_test['seniority'] != df_test['pred_sen']]\n",
        "print(f\"\\nSeniority Errors: {len(sen_errors)} / {len(df_test)} ({len(sen_errors)/len(df_test)*100:.1f}%)\")\n",
        "print(\"\\nTop Confusions:\")\n",
        "sen_confusion = sen_errors.groupby(['seniority', 'pred_sen']).size().sort_values(ascending=False).head(10)\n",
        "for (actual, pred), count in sen_confusion.items():\n",
        "    print(f\"  {actual:<15} → {pred:<15} ({count})\")\n",
        "\n",
        "# Department errors\n",
        "dept_errors = df_test[df_test['department'] != df_test['pred_dept']]\n",
        "print(f\"\\nDepartment Errors: {len(dept_errors)} / {len(df_test)} ({len(dept_errors)/len(df_test)*100:.1f}%)\")\n",
        "print(\"\\nTop Confusions:\")\n",
        "dept_confusion = dept_errors.groupby(['department', 'pred_dept']).size().sort_values(ascending=False).head(10)\n",
        "for (actual, pred), count in dept_confusion.items():\n",
        "    print(f\"  {actual:<25} → {pred:<25} ({count})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m05GXyz_DY-N"
      },
      "source": [
        "## 7. Production Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zxk5q_sGDY-O"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"PRODUCTION PREDICTIONS (more.txt)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Prepare production data\n",
        "df_prod['text_clean'] = df_prod['position'].apply(clean_text)\n",
        "prod_texts = df_prod['text_clean'].tolist()\n",
        "\n",
        "print(f\"Predicting {len(prod_texts)} samples...\")\n",
        "\n",
        "# Predictions\n",
        "prod_sen_preds, prod_sen_confs = predict_ensemble(\n",
        "    prod_texts, sen_mlp, sen_setfit, sen_prototypes, sen_label_encoder, encoder\n",
        ")\n",
        "prod_dept_preds, prod_dept_confs = predict_ensemble(\n",
        "    prod_texts, dept_mlp, dept_setfit, dept_prototypes, dept_label_encoder, encoder\n",
        ")\n",
        "\n",
        "df_prod['pred_seniority'] = prod_sen_preds\n",
        "df_prod['sen_conf'] = prod_sen_confs\n",
        "df_prod['pred_department'] = prod_dept_preds\n",
        "df_prod['dept_conf'] = prod_dept_confs\n",
        "\n",
        "print(\"\\n✓ Production predictions complete!\")\n",
        "print(\"\\nPrediction Distribution:\")\n",
        "print(\"\\nSeniority:\")\n",
        "print(df_prod['pred_seniority'].value_counts())\n",
        "print(\"\\nDepartment:\")\n",
        "print(df_prod['pred_department'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8t34xnhMDY-O"
      },
      "source": [
        "## 8. Save Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxoPUgtjDY-O"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"SAVING RESULTS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Test predictions\n",
        "test_out = df_test[['position', 'organization', 'department', 'pred_dept', 'dept_conf',\n",
        "                    'seniority', 'pred_sen', 'sen_conf']].copy()\n",
        "test_out.columns = ['position', 'organization', 'actual_dept', 'pred_dept', 'dept_conf',\n",
        "                    'actual_sen', 'pred_sen', 'sen_conf']\n",
        "test_out.to_csv('setfit_v3_concept_test.csv', index=False)\n",
        "print(\"✓ setfit_v3_concept_test.csv\")\n",
        "\n",
        "# Production predictions\n",
        "prod_out = df_prod[['position', 'organization', 'pred_department', 'dept_conf',\n",
        "                    'pred_seniority', 'sen_conf']].copy()\n",
        "prod_out.to_csv('setfit_v3_concept_production.csv', index=False)\n",
        "print(\"✓ setfit_v3_concept_production.csv\")\n",
        "\n",
        "# Save metrics\n",
        "results = {\n",
        "    'model': MODEL_NAME,\n",
        "    'approach': 'Concept Pre-Knowledge + SetFit + MLP Ensemble',\n",
        "    'seniority': {\n",
        "        'accuracy': float(sen_acc),\n",
        "        'f1_macro': float(sen_f1),\n",
        "        'f1_weighted': float(sen_f1_w)\n",
        "    },\n",
        "    'department': {\n",
        "        'accuracy': float(dept_acc),\n",
        "        'f1_macro': float(dept_f1),\n",
        "        'f1_weighted': float(dept_f1_w)\n",
        "    },\n",
        "    'data': {\n",
        "        'training': f'{len(df_sen_train)} seniority, {len(df_dept_train)} department (CSVs only)',\n",
        "        'testing': f'{len(df_test)} samples (100% testdata.txt, NEVER in training)',\n",
        "        'production': f'{len(df_prod)} samples'\n",
        "    },\n",
        "    'concept_knowledge': {\n",
        "        'seniority_prototypes': len(SEN_LABELS),\n",
        "        'department_prototypes': len(DEPT_LABELS)\n",
        "    }\n",
        "}\n",
        "\n",
        "with open('setfit_v3_concept_results.json', 'w') as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "print(\"✓ setfit_v3_concept_results.json\")\n",
        "\n",
        "# Save models\n",
        "sen_setfit.save_pretrained('setfit_v3_seniority_model')\n",
        "dept_setfit.save_pretrained('setfit_v3_department_model')\n",
        "print(\"✓ SetFit models saved\")\n",
        "\n",
        "# Save concept prototypes\n",
        "np.save('sen_prototypes.npy', sen_prototypes)\n",
        "np.save('dept_prototypes.npy', dept_prototypes)\n",
        "print(\"✓ Concept prototypes saved\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}